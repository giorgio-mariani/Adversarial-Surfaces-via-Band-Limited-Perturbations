{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Examples on SHREC14 using PointNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# built-in libraries\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "\n",
    "# third party libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as funcs\n",
    "import torch_sparse as tsparse\n",
    "\n",
    "REPO_ROOT = os.path.abspath(os.path.join(os.path.dirname(os.path.realpath('__file__')),\"..\"))\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "SRC_DIR = os.path.join(REPO_ROOT,\"src\")\n",
    "SHREC14 =  os.path.join(REPO_ROOT,\"datasets/shrec14\")\n",
    "\n",
    "#PARAMS_FILE = os.path.join(REPO_ROOT, \"model_data/real.pt\")\n",
    "ENCODER_PARAMS = os.path.join(REPO_ROOT, \"model_data/SHREC14_enc3.pt\")\n",
    "DECODER_PARAMS = os.path.join(REPO_ROOT, \"model_data/SHREC14_dec3.pt\")\n",
    "CLASSIFIER_PARAMS = os.path.join(REPO_ROOT,'model_data/SHREC14_cla3.pt')\n",
    "\n",
    "# repository modules\n",
    "sys.path.insert(0, SRC_DIR)\n",
    "import models\n",
    "import train\n",
    "import dataset\n",
    "import utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape Classification using SHREC14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = dataset.Shrec14Dataset(SHREC14,device=DEVICE, train=True, test=False)\n",
    "testdata = dataset.Shrec14Dataset(SHREC14, device=DEVICE, train=False, test=True, transform_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from models.pointnet import SimplePointNet \n",
    "\n",
    "#autoencoder\n",
    "LATENT_SPACE = 128\n",
    "NUM_POINTS = 7000\n",
    "\n",
    "# encoder\n",
    "ENC = SimplePointNet(\n",
    "    latent_dimensionality=LATENT_SPACE*2,\n",
    "    convolutional_output_dim=512,\n",
    "    conv_layer_sizes=[32, 128, 256],\n",
    "    fc_layer_sizes=[512, 256, 128],\n",
    "    transformer_positions=[0]).to(DEVICE)\n",
    "\n",
    "# decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        nn.Module.__init__(self)\n",
    "        self.fc1 = nn.Sequential(nn.Linear(LATENT_SPACE, 1024), \n",
    "                        nn.LeakyReLU(), nn.Linear(1024, 2048),\n",
    "                        nn.LeakyReLU(), nn.Linear(2048, NUM_POINTS*3))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x).view(x.shape[0],NUM_POINTS,-1)\n",
    "        xfc = x\n",
    "        return x\n",
    "DEC = Decoder().to(DEVICE)\n",
    "\n",
    "    \n",
    "# classifier\n",
    "CLA = nn.Sequential(\n",
    "    nn.Linear(LATENT_SPACE, 64), nn.ReLU(), nn.Linear(64,10)).to(DEVICE)\n",
    "\n",
    "'''\n",
    "# auto-encoder\n",
    "from ChamferDistancePytorch.chamfer3D.dist_chamfer_3D import chamfer_3DDist\n",
    "chamLoss = chamfer_3DDist()\n",
    "\n",
    "DEC = Decoder().cuda()\n",
    "model =  testdata[0].to(DEVICE)\n",
    "\n",
    "def loss_fun(data):\n",
    "    data.pos = data.pos.view(data.y.shape[0],-1,3)\n",
    "    data.oripos = data.oripos.view(data.y.shape[0],-1,3)\n",
    "\n",
    "    latent = ENC(data.to(DEVICE),None,None)\n",
    "\n",
    "    #variational\n",
    "    z_mu = latent[...,:LATENT_SPACE]\n",
    "    z_var  = latent[...,LATENT_SPACE:]\n",
    "    std = torch.exp(z_var / 2)\n",
    "    eps = torch.randn_like(std)\n",
    "    latent = eps.mul(std).add_(z_mu)       \n",
    "\n",
    "    rec = model.oripos[None,...]+DEC(latent)\n",
    "    dist1, dist2, idx1, idx2 =  chamLoss(data.oripos, rec)\n",
    "    loss = 1e2*torch.mean(dist1+dist2)\n",
    "    \n",
    "    kl_loss = 0.5 * torch.sum(torch.exp(z_var) + z_mu**2 - 1.0 - z_var)\n",
    "    loss += 1e-5*kl_loss\n",
    "        \n",
    "    pdist = lambda A, B: A.pow(2).sum(2, keepdim = True) - 2 * torch.bmm(A, B.transpose(1,2)) + B.pow(2).sum(2, keepdim = True).transpose(1,2)\n",
    "    sploss = F.relu(2e-3-pdist(rec,rec),2e-3).mean()\n",
    "\n",
    "    loss = loss + 1e2*sploss \n",
    "    return loss\n",
    "'''\n",
    "\n",
    "ENC.load_state_dict(torch.load(ENCODER_PARAMS, map_location=DEVICE))\n",
    "DEC.load_state_dict(torch.load(DECODER_PARAMS, map_location=DEVICE))\n",
    "CLA.load_state_dict(torch.load(CLASSIFIER_PARAMS, map_location=DEVICE))\n",
    "ENC.eval()\n",
    "DEC.eval()\n",
    "CLA.eval()\n",
    "\n",
    "# complete classifier, using encoder layers and classification layers\n",
    "class SHREC14Classifier(nn.Module):\n",
    "    def __init__(self, enc, cla):\n",
    "        super().__init__()\n",
    "        self.cla=cla\n",
    "        self.enc=enc\n",
    "        \n",
    "    def forward(self,pos):    \n",
    "        lsp = self.enc(pos)[...,:LATENT_SPACE]\n",
    "        return self.cla(lsp)\n",
    "MODEL = SHREC14Classifier(ENC,CLA).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to see the accuracy of the model by simply invoking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, confusion = train.evaluate(\n",
    "    eval_data=testdata, classifier=MODEL, epoch_number=1)\n",
    "\n",
    "# show accuracy\n",
    "print(accuracy)\n",
    "plt.matshow(confusion)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization procedures\n",
    "These are some visualization procedures useful for displaying triangular meshes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def visualize(pos, faces, intensity=None):\n",
    "  cpu = torch.device(\"cpu\")\n",
    "  if type(pos) != np.ndarray:\n",
    "    pos = pos.to(cpu).clone().detach().numpy()\n",
    "  if pos.shape[-1] != 3:\n",
    "    raise ValueError(\"Vertices positions must have shape [n,3]\")\n",
    "  if type(faces) != np.ndarray:\n",
    "    faces = faces.to(cpu).clone().detach().numpy()\n",
    "  if faces.shape[-1] != 3:\n",
    "    raise ValueError(\"Face indices must have shape [m,3]\") \n",
    "  if intensity is None:\n",
    "    intensity = np.ones([pos.shape[0]])\n",
    "  elif type(intensity) != np.ndarray:\n",
    "    intensity = intensity.to(cpu).clone().detach().numpy()\n",
    "\n",
    "  x, z, y = pos.T\n",
    "  i, j, k = faces.T\n",
    "\n",
    "  mesh = go.Mesh3d(x=x, y=y, z=z,\n",
    "            color='lightpink',\n",
    "            intensity=intensity,\n",
    "            opacity=1,\n",
    "            colorscale=[[0, 'gold'],[0.5, 'mediumturquoise'],[1, 'magenta']],\n",
    "            i=i, j=j, k=k,\n",
    "            showscale=True)\n",
    "  layout = go.Layout(scene=go.layout.Scene(aspectmode=\"data\")) \n",
    "\n",
    "  #pio.renderers.default=\"plotly_mimetype\"\n",
    "  fig = go.Figure(data=[mesh],\n",
    "                  layout=layout)\n",
    "  fig.update_layout(\n",
    "      autosize=True,\n",
    "      margin=dict(l=20, r=20, t=20, b=20),\n",
    "      paper_bgcolor=\"LightSteelBlue\")\n",
    "  fig.show()\n",
    "    \n",
    "def compare(pos1, faces1, pos2, faces2):\n",
    "    n,m = pos1.shape[0], pos2.shape[0]\n",
    "    tmpx = torch.cat([pos1, pos2],dim=0)\n",
    "    tmpf = torch.cat([faces1, faces2+n], dim=0)\n",
    "    color = torch.zeros([n+m],dtype=pos1.dtype, device=pos1.device)\n",
    "    color[n:] = (pos1-pos2).norm(p=2,dim=-1)\n",
    "    visualize(tmpx, tmpf,color)\n",
    "    \n",
    "def show_perturbation(adex):\n",
    "  perturbed = adex.perturbed_pos.cpu()\n",
    "  pos = adex.pos.cpu()\n",
    "  p1 = adex.logits.cpu().detach().numpy()\n",
    "  p2 = adex.perturbed_logits.cpu().detach().numpy()\n",
    "  m = min([p1.min(),p2.min()])\n",
    "  num_classes = p1.shape[0]\n",
    "  \n",
    "  x_ticks = np.array(range(num_classes),dtype=float)\n",
    "  ax = plt.subplot(111)\n",
    "  ax.bar(x_ticks-0.2, p1-m, width=0.4, color='b', align='center')\n",
    "  ax.bar(x_ticks+0.2, p2-m, width=0.4, color='y', align='center')\n",
    "  ax.legend([\"standard\",\"perturbed towards \"+str(adex.target.item())])\n",
    "  ax.set_title(\"Class Probabilities with/without Perturbation\")\n",
    "  plt.show()\n",
    "\n",
    "  color = (pos-perturbed).norm(p=2,dim=-1)\n",
    "  visualize (perturbed, adex.faces, intensity=color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Examples with Carlini&Wagner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import adversarial.carlini_wagner as cw\n",
    "from adversarial.carlini_wagner import CWBuilder, LowbandPerturbation\n",
    "\n",
    "params = {\n",
    "    CWBuilder.USETQDM:True,\n",
    "    CWBuilder.MIN_IT:100,\n",
    "    CWBuilder.LEARN_RATE:1e-4,\n",
    "    CWBuilder.ADV_COEFF:1,\n",
    "    CWBuilder.REG_COEFF:1,\n",
    "    LowbandPerturbation.EIGS_NUMBER:40}\n",
    "\n",
    "#choose random target\n",
    "while True:\n",
    "    i = random.randint(0, len(testdata)-1)\n",
    "    target = random.randint(0, testdata.num_classes-1)\n",
    "    y = testdata[i].y.item()\n",
    "    if y != target: break\n",
    "mesh = testdata[i]\n",
    "print(target)\n",
    "\n",
    "# search for adversarial example\n",
    "adex = cw.generate_adversarial_example(\n",
    "    mesh=mesh, classifier=MODEL, target=target,\n",
    "    search_iterations=1,\n",
    "    lowband_perturbation=True, \n",
    "    adversarial_loss=\"carlini_wagner\",\n",
    "    similarity_loss=\"local_euclidean\",\n",
    "    **params)\n",
    "\n",
    "show_perturbation(adex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
