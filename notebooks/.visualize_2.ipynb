{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "heatmap = go.Heatmap(z=[-1, 0, 0],colorscale='RdBu',zmid=0)\n",
    "def visualize(pos, faces, intensity=None):\n",
    "  cpu = torch.device(\"cpu\")\n",
    "  if type(pos) != np.ndarray:\n",
    "    pos = pos.to(cpu).clone().detach().numpy()\n",
    "  if pos.shape[-1] != 3:\n",
    "    raise ValueError(\"Vertices positions must have shape [n,3]\")\n",
    "  if type(faces) != np.ndarray:\n",
    "    faces = faces.to(cpu).clone().detach().numpy()\n",
    "  if faces.shape[-1] != 3:\n",
    "    raise ValueError(\"Face indices must have shape [m,3]\") \n",
    "  if intensity is None:\n",
    "    intensity = np.ones([pos.shape[0]])\n",
    "  elif type(intensity) != np.ndarray:\n",
    "    intensity = intensity.to(cpu).clone().detach().numpy()\n",
    "\n",
    "  x, z, y = pos.T\n",
    "  i, j, k = faces.T\n",
    "\n",
    "  mesh = go.Mesh3d(x=x, y=y, z=z,\n",
    "            color='lightpink',\n",
    "            intensity=intensity,\n",
    "            opacity=1,\n",
    "            colorscale=[[0, 'gold'],[0.5, 'mediumturquoise'],[1, 'magenta']],\n",
    "            i=i, j=j, k=k,\n",
    "            showscale=True)\n",
    "  layout = go.Layout(scene=go.layout.Scene(aspectmode=\"data\")) \n",
    "\n",
    "  #pio.renderers.default=\"plotly_mimetype\"\n",
    "  fig = go.Figure(data=[mesh],layout=layout)\n",
    "  fig.update_layout(\n",
    "      autosize=True,\n",
    "      margin=dict(l=20, r=20, t=20, b=20))\n",
    "  fig.show()\n",
    "\n",
    "def visualize_pointcloud(pos, color, camera=None,figname=\"fig.png\"):\n",
    "    axis = dict(backgroundcolor=\"white\",title=\"\",gridcolor=\"white\",showbackground=False,zerolinecolor=\"white\",showticklabels=False)\n",
    "    layout = go.Layout(scene=go.layout.Scene(aspectmode=\"data\",xaxis=axis, yaxis=axis,zaxis=axis,bgcolor=\"white\"))\n",
    "    \n",
    "    if isinstance(pos, torch.Tensor):\n",
    "        x,z,y = pos.t().cpu().detach().numpy()\n",
    "    elif isinstance(pos, np.ndarray):\n",
    "        x,z,y = pos.T\n",
    "    else:\n",
    "        raise ValueError()\n",
    "    if isinstance(color,torch.Tensor):\n",
    "        color = color.cpu().detach().numpy()\n",
    "\n",
    "    if camera is None:\n",
    "        camera = dict(up=dict(x=0, y=0, z=1),\n",
    "                  center=dict(x=0, y=0, z=0),\n",
    "                  eye=dict(x=1.25, y=1.25, z=1.25))\n",
    "    \n",
    "    fig = go.Figure(data=[go.Scatter3d(\n",
    "      x=x,\n",
    "      y=y,\n",
    "      z=z,\n",
    "      mode='markers',\n",
    "      marker=dict(\n",
    "          size=8,\n",
    "          color=-color,                # set color to an array/list of desired values\n",
    "          colorscale='RdBu',   # choose a colorscale\n",
    "          opacity=1\n",
    "      ))], layout=layout)\n",
    "\n",
    "    # tight layout\n",
    "    fig.update_layout(autosize=True,scene_camera=camera)\n",
    "    fig.show()\n",
    "    fig.write_image(figname,width=1600,height=1600)\n",
    "    \n",
    "\n",
    "def compare(pos1, faces1, pos2, faces2):\n",
    "    n,m = pos1.shape[0], pos2.shape[0]\n",
    "    tmpx = torch.cat([pos1, pos2],dim=0)\n",
    "    tmpf = torch.cat([faces1, faces2+n], dim=0)\n",
    "    color = torch.zeros([n+m],dtype=pos1.dtype, device=pos1.device)\n",
    "    color[n:] = (pos1-pos2).norm(p=2,dim=-1)\n",
    "    visualize(tmpx, tmpf,color)\n",
    "    \n",
    "def read_obj(filename):\n",
    "    vertices = []\n",
    "    faces = []\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in  file :\n",
    "            fc =  line[0]\n",
    "            if fc == \"#\":\n",
    "                pass\n",
    "            elif fc == \"v\":\n",
    "                vertices += [[float(s) for s in line[1:].strip().split(' ')]]\n",
    "            elif fc == \"f\":\n",
    "                faces += [[int(s) for s in line[1:].strip().split(' ')]]\n",
    "            else:\n",
    "                print(fc)\n",
    "            \n",
    "    vertices = np.array(vertices, dtype=np.float64)\n",
    "    faces = np.array(faces, dtype=np.long)\n",
    "    return vertices, faces-1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import utils\n",
    "\n",
    "prefix = \"../model_data/GeoA3_qualitative/\"\n",
    "\n",
    "def mc( x1,x2,f):\n",
    "    mc1,_,_ = utils.meancurvature(x1,f)\n",
    "    mc2,_,_ = utils.meancurvature(x2,f)\n",
    "    return (mc1-mc2).abs().sqrt()\n",
    "\n",
    "def l2(x1,x2,f):\n",
    "    return (x1-x2).norm(p=2,dim=-1)\n",
    "\n",
    "new_camera = lambda  c, r, x: dict(up=dict(x=0, y=0, z=1),\n",
    "                  center=c,eye=dict(x=c[\"x\"]+r*np.sin(x), y=c[\"y\"]+r*np.cos(x), z=1))\n",
    "\n",
    "center= dict(x=0, y=0, z=0)\n",
    "camera = new_camera(center ,2,1)\n",
    "\n",
    "def GeoA3_ours_saveimg(i,camera:dict,title:str=\"\"):\n",
    "    pos, faces =  read_obj(join(prefix,\"subject_{}_original.obj\".format(i)))\n",
    "    ppos_ours, _ = read_obj(join(prefix,\"subject_{}_adv_ours.obj\".format(i)))\n",
    "    ppos_geoa3, _ = read_obj(join(prefix,\"subject_{}_adv_GeoA3.obj\".format(i)))\n",
    "\n",
    "    pos, faces = torch.tensor(pos), torch.tensor(faces, dtype=torch.long)\n",
    "    ppos_ours,ppos_geoa3 = torch.tensor(ppos_ours),torch.tensor(ppos_geoa3)\n",
    "\n",
    "    filename_ours = join(prefix,title+\"_ours.png\")\n",
    "    filename_GeoA3 = join(prefix,title+\"_GeoA3.png\")\n",
    "    visualize_pointcloud(ppos_ours, color=l2(pos,ppos_ours,faces),camera=camera,figname=filename_ours)\n",
    "    visualize_pointcloud(ppos_geoa3, color=l2(pos,ppos_geoa3,faces),camera=camera,figname=filename_GeoA3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_78 = dict(x=0.01,y=0.38,z=0.0)\n",
    "foot_29 = dict(x=-0.05,y=0,z=-0.84)\n",
    "hand_42 = dict(x=0.32,y=-0.30,z=0.37)\n",
    "camera = new_camera(foot_29, 1, 0)\n",
    "camera[\"eye\"][\"z\"] = -0.1\n",
    "GeoA3_ours_saveimg(i=29,camera=camera,title=\"feet_29\")\n",
    "\n",
    "camera = new_camera(head_78, 2, 1)\n",
    "GeoA3_ours_saveimg(i=78,camera=camera,title=\"head_78\")\n",
    "\n",
    "camera = new_camera(hand_42, 0.75, 3)\n",
    "GeoA3_ours_saveimg(i=42,camera=camera,title=\"hand_42\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PGD EXperiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import mkdir, listdir\n",
    "from os.path import exists, join \n",
    "import random\n",
    "import tqdm\n",
    "\n",
    "import adversarial.pgd as pgd\n",
    "import adversarial.carlini_wagner as cw\n",
    "import numpy as np\n",
    "\n",
    "def save_adex(adex, y, filename):\n",
    "  ppos = adex.perturbed_pos.detach().clone().cpu().numpy()\n",
    "  pos = adex.pos.detach().clone().cpu().numpy()\n",
    "  edges = adex.edges.detach().clone().cpu().numpy()\n",
    "  faces = adex.faces.detach().clone().cpu().numpy()\n",
    "  is_successful = adex.is_successful\n",
    "  \n",
    "  data = {\"perturbed-positions\":ppos,\n",
    "   \"positions\":pos,\n",
    "   \"edges\":edges,\n",
    "   \"faces\":faces,\n",
    "    \"y\":y,\n",
    "    \"success\":is_successful,\n",
    "   \"l2\":cw.L2_distortion(adex).item(),\n",
    "   \"arap\":cw.LocallyEuclideanDistortion(K=40)(adex).item()\n",
    "   }\n",
    "  np.save(filename, data, allow_pickle=True)\n",
    "\n",
    "def pgd_experiments(projection_type, builder_type, model, data, folder=\"tmp\"):\n",
    "    projections = {\"lowband\":         pgd.lowband_filter,\n",
    "                  \"lowband-clip\":     lambda a,x: pgd.clip(a, pgd.lowband_filter(a,x)),\n",
    "                  \"lowband-clipnorm\": lambda a,x: pgd.clip_norms(a,pgd.lowband_filter(a,x)),\n",
    "                   \"none\":            lambda y,z : z,\n",
    "                  \"clip\":             pgd.clip,\n",
    "                  \"clipnorm\":         pgd.clip_norms}\n",
    "\n",
    "    builders = {\"sign\":(pgd.PGDBuilder,0.01), \"l2\":(pgd.L2PGDBuilder, 1)}\n",
    "    successes, failures = 0,0\n",
    "    \n",
    "    if not exists(folder):\n",
    "        mkdir(folder)\n",
    "    \n",
    "    for i in tqdm.tqdm(range(len(data))):\n",
    "        x = data[i].pos\n",
    "        e = data[i].edge_index.t()\n",
    "        f = data[i].face.t() \n",
    "        y = data[i].y\n",
    "            \n",
    "        if model(x).argmax() == y:\n",
    "            tmp, alpha = builders[builder_type]\n",
    "            builder = tmp().set_iterations(7).set_epsilon(0.045).set_alpha(alpha).set_eigs_number(50)\n",
    "            builder.set_projection(projections[projection_type])\n",
    "            builder.set_mesh(x,e,f).set_classifier(model)\n",
    "            adex = builder.build(usetqdm=\"standard\")\n",
    "            print(\"successful: {}\".format(adex.is_successful))\n",
    "            #print(\"adversarial example's prediction: {}\".format(model(adex.perturbed_pos).argmax()))\n",
    "            #print(\"ground-truth: {}\".format(model(adex.pos).argmax()))\n",
    "            #visualize(adex.pos, f, (adex.pos-adex.perturbed_pos).norm(dim=-1,p=2))\n",
    "            #compare(adex.pos, f, adex.perturbed_pos, f)\n",
    "            \n",
    "            filename = join(folder, \"adversarial_{}_b{}_p{}\".format(i, builder_type, projection_type))\n",
    "            save_adex(adex, y, filename)\n",
    "            successes +=1\n",
    "        else:\n",
    "            print(\"skip\")\n",
    "            failures +=1\n",
    "    return successes/(successes+failures)\n",
    "\n",
    "\n",
    "pgd_experiments(\"lowband\",\"l2\", model=model, data=testdata, folder=join(REPO_ROOT,\"pgd_tests_l2_lowband\"))\n",
    "pgd_experiments(\"none\",\"l2\", model=model, data=testdata, folder=join(REPO_ROOT,\"pgd_tests_l2\"))\n",
    "\n",
    "pgd_experiments(\"lowband\",\"sign\", model=model, data=testdata, folder=join(REPO_ROOT,\"pgd_tests_sign_lowband\"))\n",
    "pgd_experiments(\"none\", \"sign\", model=model, data=testdata, folder=join(REPO_ROOT,\"pgd_tests_sign\"))\n",
    "                                                                    \n",
    "                                                                    \n",
    "pgd_experiments(\"lowband-clipnorm\",\"l2\", model=model, data=testdata, folder=join(REPO_ROOT,\"pgd_tests_l2_lowband-clipnorm\"))\n",
    "pgd_experiments(\"clipnorm\",\"l2\", model=model, data=testdata, folder=join(REPO_ROOT,\"pgd_tests_l2_clipnorm\"))\n",
    "                                                                    \n",
    "                                                                    \n",
    "pgd_experiments(\"lowband-clipnorm\",\"sign\", model=model, data=testdata, folder=join(REPO_ROOT,\"pgd_tests_sign_lowband-clipnorm\"))\n",
    "pgd_experiments(\"clipnorm\",\"sign\", model=model, data=testdata, folder=join(REPO_ROOT,\"pgd_tests_sign_clipnorm\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
