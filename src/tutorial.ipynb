{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "## 1) Targeted Adversarial Examples (Carlini & Wagner and related methods)\n",
    "First, we need to import the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# built-in libraries\n",
    "import os \n",
    "\n",
    "# third party libraries\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import tqdm\n",
    "import torch \n",
    "import torch.nn.functional as func\n",
    "\n",
    "# repository modules\n",
    "import models\n",
    "import train\n",
    "import dataset\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training and test data is loaded in memory using the `dataset` local module. Before using the FAUST dataset download it from [here](http://faust.is.tue.mpg.de/) and place it in `{repository-root}/datasets/faust/raw/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Dataset not found. Please download ['tr_reg_000.ply', 'tr_reg_001.ply', 'tr_reg_002.ply', 'tr_reg_003.ply', 'tr_reg_004.ply', 'tr_reg_005.ply', 'tr_reg_006.ply', 'tr_reg_007.ply', 'tr_reg_008.ply', 'tr_reg_009.ply', 'tr_reg_010.ply', 'tr_reg_011.ply', 'tr_reg_012.ply', 'tr_reg_013.ply', 'tr_reg_014.ply', 'tr_reg_015.ply', 'tr_reg_016.ply', 'tr_reg_017.ply', 'tr_reg_018.ply', 'tr_reg_019.ply', 'tr_reg_020.ply', 'tr_reg_021.ply', 'tr_reg_022.ply', 'tr_reg_023.ply', 'tr_reg_024.ply', 'tr_reg_025.ply', 'tr_reg_026.ply', 'tr_reg_027.ply', 'tr_reg_028.ply', 'tr_reg_029.ply', 'tr_reg_030.ply', 'tr_reg_031.ply', 'tr_reg_032.ply', 'tr_reg_033.ply', 'tr_reg_034.ply', 'tr_reg_035.ply', 'tr_reg_036.ply', 'tr_reg_037.ply', 'tr_reg_038.ply', 'tr_reg_039.ply', 'tr_reg_040.ply', 'tr_reg_041.ply', 'tr_reg_042.ply', 'tr_reg_043.ply', 'tr_reg_044.ply', 'tr_reg_045.ply', 'tr_reg_046.ply', 'tr_reg_047.ply', 'tr_reg_048.ply', 'tr_reg_049.ply', 'tr_reg_050.ply', 'tr_reg_051.ply', 'tr_reg_052.ply', 'tr_reg_053.ply', 'tr_reg_054.ply', 'tr_reg_055.ply', 'tr_reg_056.ply', 'tr_reg_057.ply', 'tr_reg_058.ply', 'tr_reg_059.ply', 'tr_reg_060.ply', 'tr_reg_061.ply', 'tr_reg_062.ply', 'tr_reg_063.ply', 'tr_reg_064.ply', 'tr_reg_065.ply', 'tr_reg_066.ply', 'tr_reg_067.ply', 'tr_reg_068.ply', 'tr_reg_069.ply', 'tr_reg_070.ply', 'tr_reg_071.ply', 'tr_reg_072.ply', 'tr_reg_073.ply', 'tr_reg_074.ply', 'tr_reg_075.ply', 'tr_reg_076.ply', 'tr_reg_077.ply', 'tr_reg_078.ply', 'tr_reg_079.ply', 'tr_reg_080.ply', 'tr_reg_081.ply', 'tr_reg_082.ply', 'tr_reg_083.ply', 'tr_reg_084.ply', 'tr_reg_085.ply', 'tr_reg_086.ply', 'tr_reg_087.ply', 'tr_reg_088.ply', 'tr_reg_089.ply', 'tr_reg_090.ply', 'tr_reg_091.ply', 'tr_reg_092.ply', 'tr_reg_093.ply', 'tr_reg_094.ply', 'tr_reg_095.ply', 'tr_reg_096.ply', 'tr_reg_097.ply', 'tr_reg_098.ply', 'tr_reg_099.ply'] from http://faust.is.tue.mpg.de/ and move it to /home/lcosmo/PROJECTS/Adversarial/Adversarial-Examples-on-Meshes/datasets/faust/raw",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-316500f268ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mPARAMS_FILE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mREPO_ROOT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model_data/data.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtraindata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFaustDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFAUST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtestdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFaustDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFAUST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtransform_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PROJECTS/Adversarial/Adversarial-Examples-on-Meshes/src/dataset/faust.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, device, train, test, transform_data)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m# center each mesh into its centroid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mpre_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/torch_geometric/data/in_memory_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[1;32m     51\u001b[0m                  pre_filter=None):\n\u001b[1;32m     52\u001b[0m         super(InMemoryDataset, self).__init__(root, transform, pre_transform,\n\u001b[0;32m---> 53\u001b[0;31m                                               pre_filter)\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'download'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'process'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36m_download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PROJECTS/Adversarial/Adversarial-Examples-on-Meshes/src/dataset/faust.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         raise RuntimeError(\n\u001b[0;32m---> 58\u001b[0;31m             'Dataset not found. Please download {} from {} and move it to {}'.format(self.raw_file_names, self.url, self.raw_dir))\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Dataset not found. Please download ['tr_reg_000.ply', 'tr_reg_001.ply', 'tr_reg_002.ply', 'tr_reg_003.ply', 'tr_reg_004.ply', 'tr_reg_005.ply', 'tr_reg_006.ply', 'tr_reg_007.ply', 'tr_reg_008.ply', 'tr_reg_009.ply', 'tr_reg_010.ply', 'tr_reg_011.ply', 'tr_reg_012.ply', 'tr_reg_013.ply', 'tr_reg_014.ply', 'tr_reg_015.ply', 'tr_reg_016.ply', 'tr_reg_017.ply', 'tr_reg_018.ply', 'tr_reg_019.ply', 'tr_reg_020.ply', 'tr_reg_021.ply', 'tr_reg_022.ply', 'tr_reg_023.ply', 'tr_reg_024.ply', 'tr_reg_025.ply', 'tr_reg_026.ply', 'tr_reg_027.ply', 'tr_reg_028.ply', 'tr_reg_029.ply', 'tr_reg_030.ply', 'tr_reg_031.ply', 'tr_reg_032.ply', 'tr_reg_033.ply', 'tr_reg_034.ply', 'tr_reg_035.ply', 'tr_reg_036.ply', 'tr_reg_037.ply', 'tr_reg_038.ply', 'tr_reg_039.ply', 'tr_reg_040.ply', 'tr_reg_041.ply', 'tr_reg_042.ply', 'tr_reg_043.ply', 'tr_reg_044.ply', 'tr_reg_045.ply', 'tr_reg_046.ply', 'tr_reg_047.ply', 'tr_reg_048.ply', 'tr_reg_049.ply', 'tr_reg_050.ply', 'tr_reg_051.ply', 'tr_reg_052.ply', 'tr_reg_053.ply', 'tr_reg_054.ply', 'tr_reg_055.ply', 'tr_reg_056.ply', 'tr_reg_057.ply', 'tr_reg_058.ply', 'tr_reg_059.ply', 'tr_reg_060.ply', 'tr_reg_061.ply', 'tr_reg_062.ply', 'tr_reg_063.ply', 'tr_reg_064.ply', 'tr_reg_065.ply', 'tr_reg_066.ply', 'tr_reg_067.ply', 'tr_reg_068.ply', 'tr_reg_069.ply', 'tr_reg_070.ply', 'tr_reg_071.ply', 'tr_reg_072.ply', 'tr_reg_073.ply', 'tr_reg_074.ply', 'tr_reg_075.ply', 'tr_reg_076.ply', 'tr_reg_077.ply', 'tr_reg_078.ply', 'tr_reg_079.ply', 'tr_reg_080.ply', 'tr_reg_081.ply', 'tr_reg_082.ply', 'tr_reg_083.ply', 'tr_reg_084.ply', 'tr_reg_085.ply', 'tr_reg_086.ply', 'tr_reg_087.ply', 'tr_reg_088.ply', 'tr_reg_089.ply', 'tr_reg_090.ply', 'tr_reg_091.ply', 'tr_reg_092.ply', 'tr_reg_093.ply', 'tr_reg_094.ply', 'tr_reg_095.ply', 'tr_reg_096.ply', 'tr_reg_097.ply', 'tr_reg_098.ply', 'tr_reg_099.ply'] from http://faust.is.tue.mpg.de/ and move it to /home/lcosmo/PROJECTS/Adversarial/Adversarial-Examples-on-Meshes/datasets/faust/raw"
     ]
    }
   ],
   "source": [
    "REPO_ROOT = os.path.join(os.path.dirname(os.path.realpath('__file__')),\"..\")\n",
    "FAUST = os.path.join(REPO_ROOT,\"datasets/faust\")\n",
    "PARAMS_FILE = os.path.join(REPO_ROOT, \"model_data/data.pt\")\n",
    "\n",
    "traindata = dataset.FaustDataset(FAUST, train=True, test=False, transform_data=True)\n",
    "testdata = dataset.FaustDataset(FAUST, train=False, test=True,  transform_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can define the classifier for the human pose classefication task; download the classifier parameters from [here](https://drive.google.com/open?id=1IllCPPPcqFL3v8BDxCyswzEpxoGyXvMe). Move these parameters in `{repository-root}/model_data/data.pt` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.ChebnetClassifier(\n",
    "    param_conv_layers=[128,128,64,64],\n",
    "    D_t = traindata.downscale_matrices,\n",
    "    E_t = traindata.downscaled_edges,\n",
    "    num_classes = traindata.num_classes,\n",
    "    parameters_file=PARAMS_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and evaluation can be done through the `train` local module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train network\n",
    "train.train(\n",
    "    train_data=traindata,\n",
    "    classifier=model,\n",
    "    parameters_file=PARAMS_FILE,\n",
    "    epoch_number=0)\n",
    "\n",
    "#compute accuracy\n",
    "accuracy, confusion_matrix = train.evaluate(eval_data=testdata, classifier=model)\n",
    "\n",
    "print(accuracy)\n",
    "plt.matshow(confusion_matrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Targeted Adversarial Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import adversarial.carlini_wagner as cw\n",
    "from adversarial.carlini_wagner import CWBuilder, generate_adversarial_example # module containing the adversarial targeted algorithm\n",
    "\n",
    "# get a random mesh from the dataset and a random target class\n",
    "import random\n",
    "i = random.randint(0, len(testdata)-1)\n",
    "x = testdata[i].pos\n",
    "e = testdata[i].edge_index.t() # needs to be transposed\n",
    "f = testdata[i].face.t() # needs to be transposed\n",
    "y = testdata[i].y\n",
    "t = random.randint(0, testdata.num_classes-1)\n",
    "eigs_num = 36\n",
    "\n",
    "# configure adversarial example components\n",
    "builder = CWBuilder(search_iterations=1)\n",
    "builder.set_classifier(model)\n",
    "builder.set_mesh(x, e, f)\n",
    "builder.set_target(t)\n",
    "builder.set_similarity_loss(cw.LocalEuclideanSimilarity)\n",
    "params = {\n",
    "    CWBuilder.USETQDM:True,CWBuilder.MIN_IT:100,\n",
    "    CWBuilder.LEARN_RATE:1e-4,CWBuilder.ADV_COEFF:1e-2}\n",
    "\n",
    "adex = builder.build(**params)\n",
    "print(\"adversarial attack: \"+(\"successful\" if adex.is_successful else \"unsuccessful\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(adex.perturbed_pos, f, (adex.pos -adex.perturbed_pos).norm(p=2,dim=-1))\n",
    "compare(adex.perturbed_pos, adex.faces, adex.pos, adex.faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can finally see the actual adversarial example using **Plotly** (note: you need to install plotly before-hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "def visualize(pos, faces, intensity=None):\n",
    "  cpu = torch.device(\"cpu\")\n",
    "  if type(pos) != np.ndarray:\n",
    "    pos = pos.to(cpu).clone().detach().numpy()\n",
    "  if pos.shape[-1] != 3:\n",
    "    raise ValueError(\"Vertices positions must have shape [n,3]\")\n",
    "  if type(faces) != np.ndarray:\n",
    "    faces = faces.to(cpu).clone().detach().numpy()\n",
    "  if faces.shape[-1] != 3:\n",
    "    raise ValueError(\"Face indices must have shape [m,3]\") \n",
    "  if intensity is None:\n",
    "    intensity = np.ones([pos.shape[0]])\n",
    "  elif type(intensity) != np.ndarray:\n",
    "    intensity = intensity.to(cpu).clone().detach().numpy()\n",
    "\n",
    "  x, z, y = pos.T\n",
    "  i, j, k = faces.T\n",
    "\n",
    "  mesh = go.Mesh3d(x=x, y=y, z=z,\n",
    "            color='lightpink',\n",
    "            intensity=intensity,\n",
    "            opacity=1,\n",
    "            colorscale=[[0, 'gold'],[0.5, 'mediumturquoise'],[1, 'magenta']],\n",
    "            i=i, j=j, k=k,\n",
    "            showscale=True)\n",
    "  layout = go.Layout(scene=go.layout.Scene(aspectmode=\"data\")) \n",
    "\n",
    "  #pio.renderers.default=\"plotly_mimetype\"\n",
    "  fig = go.Figure(data=[mesh],\n",
    "                  layout=layout)\n",
    "  fig.update_layout(\n",
    "      autosize=True,\n",
    "      margin=dict(l=20, r=20, t=20, b=20),\n",
    "      paper_bgcolor=\"LightSteelBlue\")\n",
    "  fig.show()\n",
    "    \n",
    "def compare(pos1, faces1, pos2, faces2):\n",
    "    n,m = pos1.shape[0], pos2.shape[0]\n",
    "    tmpx = torch.cat([pos1, pos2],dim=0)\n",
    "    tmpf = torch.cat([faces1, faces2+n], dim=0)\n",
    "    color = torch.zeros([n+m],dtype=pos1.dtype, device=pos1.device)\n",
    "    color[n:] = (pos1-pos2).norm(p=2,dim=-1)\n",
    "    visualize(tmpx, tmpf,color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "i = random.randint(0, len(testdata)-1)\n",
    "mesh = testdata[i]\n",
    "t = random.randint(0, testdata.num_classes-1)\n",
    "\n",
    "generate_adversarial_example(mesh)\n",
    "visualize(adex.perturbed_pos, f, (x-adex.perturbed_pos).norm(p=2,dim=-1))\n",
    "compare(adex.pos, f, adex.perturbed_pos,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projected Gradient Descent Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import mkdir, listdir\n",
    "from os.path import exists, join \n",
    "import random\n",
    "import tqdm\n",
    "\n",
    "import adversarial.pgd as pgd\n",
    "import adversarial.carlini_wagner as cw\n",
    "import numpy as np\n",
    "\n",
    "def save_adex(adex, y, filename):\n",
    "  ppos = adex.perturbed_pos.detach().clone().cpu().numpy()\n",
    "  pos = adex.pos.detach().clone().cpu().numpy()\n",
    "  edges = adex.edges.detach().clone().cpu().numpy()\n",
    "  faces = adex.faces.detach().clone().cpu().numpy()\n",
    "  is_successful = adex.is_successful\n",
    "  \n",
    "  data = {\"perturbed-positions\":ppos,\n",
    "   \"positions\":pos,\n",
    "   \"edges\":edges,\n",
    "   \"faces\":faces,\n",
    "    \"y\":y,\n",
    "    \"success\":is_successful,\n",
    "   \"l2\":cw.L2_distortion(adex).item(),\n",
    "   \"arap\":cw.LocallyEuclideanDistortion(K=40)(adex).item()\n",
    "   }\n",
    "  np.save(filename, data, allow_pickle=True)\n",
    "\n",
    "def pgd_experiments(projection_type, builder_type, model, data, folder=\"tmp\"):\n",
    "    projections = {\"lowband\":         pgd.lowband_filter,\n",
    "                  \"lowband-clip\":     lambda a,x: pgd.clip(a, pgd.lowband_filter(a,x)),\n",
    "                  \"lowband-clipnorm\": lambda a,x: pgd.clip_norms(a,pgd.lowband_filter(a,x)),\n",
    "                   \"none\":            lambda y,z : z,\n",
    "                  \"clip\":             pgd.clip,\n",
    "                  \"clipnorm\":         pgd.clip_norms}\n",
    "\n",
    "    builders = {\"sign\":(pgd.PGDBuilder,0.01), \"l2\":(pgd.L2PGDBuilder, 1)}\n",
    "    successes, failures = 0,0\n",
    "    \n",
    "    if not exists(folder):\n",
    "        mkdir(folder)\n",
    "    \n",
    "    for i in tqdm.tqdm(range(len(data))):\n",
    "        x = data[i].pos\n",
    "        e = data[i].edge_index.t()\n",
    "        f = data[i].face.t() \n",
    "        y = data[i].y\n",
    "            \n",
    "        if model(x).argmax() == y:\n",
    "            tmp, alpha = builders[builder_type]\n",
    "            builder = tmp().set_iterations(7).set_epsilon(0.045).set_alpha(alpha).set_eigs_number(50)\n",
    "            builder.set_projection(projections[projection_type])\n",
    "            builder.set_mesh(x,e,f).set_classifier(model)\n",
    "            adex = builder.build(usetqdm=\"standard\")\n",
    "            print(\"successful: {}\".format(adex.is_successful))\n",
    "            #print(\"adversarial example's prediction: {}\".format(model(adex.perturbed_pos).argmax()))\n",
    "            #print(\"ground-truth: {}\".format(model(adex.pos).argmax()))\n",
    "            #visualize(adex.pos, f, (adex.pos-adex.perturbed_pos).norm(dim=-1,p=2))\n",
    "            #compare(adex.pos, f, adex.perturbed_pos, f)\n",
    "            \n",
    "            filename = join(folder, \"adversarial_{}_b{}_p{}\".format(i, builder_type, projection_type))\n",
    "            save_adex(adex, y, filename)\n",
    "            successes +=1\n",
    "        else:\n",
    "            print(\"skip\")\n",
    "            failures +=1\n",
    "    return successes/(successes+failures)\n",
    "\n",
    "\n",
    "pgd_experiments(\"lowband\",\"l2\", model=model, data=testdata, folder=join(REPO_ROOT,\"pgd_tests_l2_lowband\"))\n",
    "pgd_experiments(\"none\",\"l2\", model=model, data=testdata, folder=join(REPO_ROOT,\"pgd_tests_l2\"))\n",
    "\n",
    "pgd_experiments(\"lowband\",\"sign\", model=model, data=testdata, folder=join(REPO_ROOT,\"pgd_tests_sign_lowband\"))\n",
    "pgd_experiments(\"none\", \"sign\", model=model, data=testdata, folder=join(REPO_ROOT,\"pgd_tests_sign\"))\n",
    "                                                                    \n",
    "                                                                    \n",
    "pgd_experiments(\"lowband-clipnorm\",\"l2\", model=model, data=testdata, folder=join(REPO_ROOT,\"pgd_tests_l2_lowband-clipnorm\"))\n",
    "pgd_experiments(\"clipnorm\",\"l2\", model=model, data=testdata, folder=join(REPO_ROOT,\"pgd_tests_l2_clipnorm\"))\n",
    "                                                                    \n",
    "                                                                    \n",
    "pgd_experiments(\"lowband-clipnorm\",\"sign\", model=model, data=testdata, folder=join(REPO_ROOT,\"pgd_tests_sign_lowband-clipnorm\"))\n",
    "pgd_experiments(\"clipnorm\",\"sign\", model=model, data=testdata, folder=join(REPO_ROOT,\"pgd_tests_sign_clipnorm\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Untargeted (FSGM and related methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adversarial.pgd import generate_adversarial_example\n",
    "import random\n",
    "i = random.randint(0, len(testdata)-1)\n",
    "mesh = testdata[i]\n",
    "\n",
    "args = {PGDBuilder.IT:5, \"eigs_num\":36, \"epsilon\":0.03}\n",
    "adex = generate_adversarial_example(mesh, model, alpha=0.03, **args, clip_transform=\"norm\", lowband_transform=\"dynamic\", gradient_transform=\"l2\")\n",
    "\n",
    "visualize(adex.perturbed_pos, f, (adex.pos -adex.perturbed_pos).norm(p=2,dim=-1))\n",
    "print(adex.is_successful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.misc import  pos_areas\n",
    "\n",
    "pos = mesh.pos\n",
    "face = mesh.face.t()\n",
    "posareas = pos_areas(pos, face)\n",
    "visualize(pos, face, posareas)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
