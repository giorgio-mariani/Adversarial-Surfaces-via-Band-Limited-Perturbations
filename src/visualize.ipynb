{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "import torch \n",
    "import torch.nn.functional as func\n",
    "\n",
    "import misc.faust as faust\n",
    "import models\n",
    "\n",
    "FAUST = \"../../Downloads/Mesh-Datasets/MyFaustDataset\"\n",
    "\n",
    "dataset = faust.FaustDataset(FAUST)\n",
    "D = dataset.downscale_matrices\n",
    "E = dataset.downscaled_edges\n",
    "F = dataset.downscaled_faces\n",
    "num_classes = 10\n",
    "lastlayernodes = D[-1].shape[0] #NOTE this is the number of nodes after the last convolutional layer\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = models.ChebyNet(lastlayernodes, num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def visualize(mesh, D=None, F=None, scale_index=0,title=\"\"):\n",
    "    \"\"\"\n",
    "    visualize input mesh.\n",
    "    \n",
    "    The input lists D and F are respectively the downscale matrices and the faces of the downscaled\n",
    "    mesh. The scale_index parameter indicates which downscaling matrix should be used, if scale_index=0 then\n",
    "    no downscaling is applied (scale_index must be less then or equal to the length of D and F).\n",
    "    \n",
    "    NOTE: if scale_index is 0 then the parameters F and D are not necessary and can simply have value to None.\n",
    "    \"\"\"\n",
    "    \n",
    "    pos = mesh.pos\n",
    "    if scale_index == 0:\n",
    "        f = mesh.face\n",
    "    else:\n",
    "        f = F[scale_index-1]\n",
    "        for j in range(scale_index):\n",
    "            pos = torch.sparse.mm(D[j], pos) #transform graph signal (vertex positions) to downscaled graph\n",
    "\n",
    "    x,y,z = pos[:,0], pos[:,1], pos[:,2]\n",
    "    i,j,k = f[0,:], f[1,:], f[2,:]\n",
    "    mesh = go.Mesh3d(x=x, y=z, z=y,\n",
    "              color='lightpink', \n",
    "              opacity=1,\n",
    "              i=i, j=j, k=k,\n",
    "              showscale=True)\n",
    "    layout = go.Layout(scene=go.layout.Scene(aspectmode=\"data\")) \n",
    "\n",
    "    #pio.renderers.default=\"plotly_mimetype\"\n",
    "    fig = go.Figure(data=[mesh],\n",
    "                   layout=layout)\n",
    "    fig.update_layout(\n",
    "        autosize=True,\n",
    "        margin=dict(l=20, r=20, t=20, b=20),\n",
    "        paper_bgcolor=\"LightSteelBlue\")\n",
    "    fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "invalid Figure property: title",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-9f092a650e43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"epoch number: \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mvisualize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscale_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-d7f6bd7ffec9>\u001b[0m in \u001b[0;36mvisualize\u001b[1;34m(mesh, D, F, scale_index, title)\u001b[0m\n\u001b[0;32m     34\u001b[0m     fig = go.Figure(data=[mesh],\n\u001b[0;32m     35\u001b[0m                    \u001b[0mlayout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m                    title=title)\n\u001b[0m\u001b[0;32m     37\u001b[0m     fig.update_layout(\n\u001b[0;32m     38\u001b[0m         \u001b[0mautosize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\plotly\\graph_objs\\_figure.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, layout, frames, skip_invalid, **kwargs)\u001b[0m\n\u001b[0;32m    606\u001b[0m             \u001b[1;32mis\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mAND\u001b[0m \u001b[0mskip_invalid\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m         \"\"\"\n\u001b[1;32m--> 608\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_invalid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m     def add_area(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\plotly\\basedatatypes.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, layout_plotly, frames, skip_invalid, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mskip_invalid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"invalid Figure property: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[1;31m# Magic Methods\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: invalid Figure property: title"
     ]
    }
   ],
   "source": [
    "# train module\n",
    "model.train()\n",
    "\n",
    "# meters\n",
    "loss_values = []\n",
    "\n",
    "#Train process\n",
    "for epoch in range(1):\n",
    "    print(\"epoch number: \"+str(epoch))\n",
    "    for data in tqdm.tqdm(dataset):\n",
    "        visualize(data, F=F, D=D,scale_index=1)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data, E, D)\n",
    "        out = out.view(1,-1)\n",
    "        \n",
    "        \n",
    "        loss = criterion(out, data.y)\n",
    "        loss_values.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
