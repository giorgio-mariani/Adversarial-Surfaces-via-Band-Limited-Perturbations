{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# built-in libraries\n",
    "import os \n",
    "\n",
    "# third party libraries\n",
    "import torch\n",
    "\n",
    "# local modules\n",
    "import dataset\n",
    "import models\n",
    "import train\n",
    "\n",
    "SHREC14 =  \"../../Downloads/Mesh-Datasets/MyShrec14\"\n",
    "PARAMS_FILE = \"../model_data/SHREC14.pt\"\n",
    "\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape Classification using SHREC14\n",
    "It is necessary to train the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = dataset.Shrec14Dataset(SHREC14, device=DEVICE, train=True, test=False)\n",
    "testdata = dataset.Shrec14Dataset(SHREC14, device=DEVICE, train=False, test=True)\n",
    "\n",
    "MODEL = models.chebynet.ChebnetClassifier_SHREC14(\n",
    "        nums_conv_units=[32,32,16,16],\n",
    "        num_classes=traindata.num_classes,\n",
    "        parameters_file=PARAMS_FILE)\n",
    "MODEL.to(DEVICE)\n",
    "\n",
    "\n",
    "#train network\n",
    "train.train_SHREC14(\n",
    "    train_data=traindata,\n",
    "    classifier=MODEL,\n",
    "    parameters_file=PARAMS_FILE,\n",
    "    learning_rate=3e-4,\n",
    "    epoch_number=10)\n",
    "\n",
    "accuracy, confusion = train.evaluate_SHREC14(\n",
    "    eval_data=testdata,\n",
    "    classifier=MODEL,\n",
    "    epoch_number=2)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(accuracy)\n",
    "plt.matshow(confusion)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape retrival using SHREC14\n",
    "In the following cell, it's shown how to train a classifier for identification of a subject. The main difference is in the dataset ground-truths, and its subdivision in test/training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS_FILE = \"../model_data/SHREC14_retrival.pt\"\n",
    "\n",
    "traindata = dataset.Shrec14Dataset_retrivial(SHREC14, device=DEVICE, train=True, test=False)\n",
    "testdata = dataset.Shrec14Dataset_retrivial(SHREC14, device=DEVICE, train=False, test=True)\n",
    "\n",
    "MODEL = models.chebynet.ChebnetClassifier_SHREC14(\n",
    "        nums_conv_units=[32,32,16,16],\n",
    "        num_classes=traindata.num_classes,\n",
    "        parameters_file=PARAMS_FILE,\n",
    "        K=20)\n",
    "MODEL.to(DEVICE)\n",
    "\n",
    "#train network\n",
    "train.train_SHREC14(\n",
    "    train_data=traindata,\n",
    "    classifier=MODEL,\n",
    "    parameters_file=PARAMS_FILE,\n",
    "    learning_rate=3e-4,\n",
    "    epoch_number=0)\n",
    "\n",
    "accuracy, confusion = train.evaluate_SHREC14(\n",
    "    eval_data=traindata,\n",
    "    classifier=MODEL,\n",
    "    epoch_number=1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(accuracy)\n",
    "plt.matshow(confusion)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "def visualize(pos, faces, intensity=None):\n",
    "  cpu = torch.device(\"cpu\")\n",
    "  if type(pos) != np.ndarray:\n",
    "    pos = pos.to(cpu).clone().detach().numpy()\n",
    "  if pos.shape[-1] != 3:\n",
    "    raise ValueError(\"Vertices positions must have shape [n,3]\")\n",
    "  if type(faces) != np.ndarray:\n",
    "    faces = faces.to(cpu).clone().detach().numpy()\n",
    "  if faces.shape[-1] != 3:\n",
    "    raise ValueError(\"Face indices must have shape [m,3]\") \n",
    "  if intensity is None:\n",
    "    intensity = np.ones([pos.shape[0]])\n",
    "  elif type(intensity) != np.ndarray:\n",
    "    intensity = intensity.to(cpu).clone().detach().numpy()\n",
    "\n",
    "  x, z, y = pos.T\n",
    "  i, j, k = faces.T\n",
    "\n",
    "  mesh = go.Mesh3d(x=x, y=y, z=z,\n",
    "            color='lightpink',\n",
    "            intensity=intensity,\n",
    "            opacity=1,\n",
    "            colorscale=[[0, 'gold'],[0.5, 'mediumturquoise'],[1, 'magenta']],\n",
    "            i=i, j=j, k=k,\n",
    "            showscale=True)\n",
    "  layout = go.Layout(scene=go.layout.Scene(aspectmode=\"data\")) \n",
    "\n",
    "  #pio.renderers.default=\"plotly_mimetype\"\n",
    "  fig = go.Figure(data=[mesh],\n",
    "                  layout=layout)\n",
    "  fig.update_layout(\n",
    "      autosize=True,\n",
    "      margin=dict(l=20, r=20, t=20, b=20),\n",
    "      paper_bgcolor=\"LightSteelBlue\")\n",
    "  fig.show()\n",
    "    \n",
    "def compare(pos1, faces1, pos2, faces2):\n",
    "    n,m = pos1.shape[0], pos2.shape[0]\n",
    "    tmpx = torch.cat([pos1, pos2],dim=0)\n",
    "    tmpf = torch.cat([faces1, faces2+n], dim=0)\n",
    "    color = torch.zeros([n+m],dtype=pos1.dtype, device=pos1.device)\n",
    "    color[n:] = (pos1-pos2).norm(p=2,dim=-1)\n",
    "    visualize(tmpx, tmpf,color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adversarial examples\n",
    "## Carlini & Wagner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import adversarial.carlini_wagner as cw\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def get_classifier(data, mesh_index): #IMPORTANT THIS IS A TRICK, NOT A GOOD PRACTICE\n",
    "    I = [(i.to(DEVICE),v.to(DEVICE), s) for (i,v,s) in data.downscale_matrices[mesh_index]]\n",
    "    E = [ e .to(DEVICE) for e in data.downscaled_edges[mesh_index]]\n",
    "    return  lambda x:  MODEL(Data(pos=x, edge_index=data[mesh_index].edge_index, y=data[mesh_index].y), I, E)\n",
    "\n",
    "def CW_adversarial_example(\n",
    "    mesh_index=0,\n",
    "    target_class=None,\n",
    "    data=testdata,\n",
    "    perturbation=\"lowband\",\n",
    "    distortion=\"local_euclidean\",\n",
    "    eigenvecs_number=36,\n",
    "    adversarial_coefficient:float=\"default\",\n",
    "    regularization_coefficient:float=\"default\",\n",
    "    learning_rate:float=5e-5,\n",
    "    minimization_iterations=1000,\n",
    "    tuning_iterations=3):\n",
    "    \"\"\"\n",
    "    Create an adversarial example using the C&W method.\n",
    "    \n",
    "    Arguments:\n",
    "     - data: the dataset containing the mesh used during the adversarial attack.\n",
    "     - mesh_index: index (in data) of the mesh to perturb.\n",
    "     - target_class: class goal for the targeted adversarial attack.\n",
    "     - perturbation: type of perturbation, assumes values 'lowband' or 'vertex'\n",
    "     - distortion: type of distortion, assumes values 'L2' or 'local_euclidean'.\n",
    "     - eigenvecs_number: number of eigenvalues used for the lowband perturbation.\n",
    "     - adversarial_coefficient: coefficient used by the adversarial term in C&W.\n",
    "     - regularization_coefficient: coefficient used for the centroid regularization term for 'local_euclidean'\n",
    "     - learning_rate: learning rate for the gradient descent iterations.\n",
    "     - miimization_iterations: number of gradient descent iterations.\n",
    "     - tuning_iterations: number of iterations used to tune the adversarial coefficient.\n",
    "     \n",
    "    Returns:\n",
    "     - adex: aversarial example. \n",
    "    \"\"\"\n",
    "    \n",
    "    #check input consistency:\n",
    "    if perturbation not in  [\"lowband\",\"vertex\"]:\n",
    "        raise ValueError(\"Invalid input for argument 'perturbation'. Must either be 'lowband' or 'vertex'!\")\n",
    "        \n",
    "    if distortion not in  [\"L2\",\"local_euclidean\"]:\n",
    "        raise ValueError(\"Invalid input for argument 'distortion'. Must either be 'L2' or 'local_euclidean'!\")\n",
    "        \n",
    "    if adversarial_coefficient != \"default\" and not isinstance(adversarial_coefficient, float):\n",
    "        raise ValueError(\"Invalid input for argument 'adversarial_coefficient'. Must either be the string 'default' or any floating point number!\")\n",
    "    \n",
    "    if regularization_coefficient != \"default\" and not isinstance(regularization_coefficient, float):\n",
    "        raise ValueError(\"Invalid input for argument 'regularization_coefficient'. Must either be the string 'default' or any floating point number!\")\n",
    "\n",
    "    if adversarial_coefficient == \"default\":\n",
    "        if distortion == \"L2\":\n",
    "            adversarial_coefficient = 5e-3\n",
    "        elif distortion == \"local_euclidean\":\n",
    "            adversarial_coefficient = 5e-7\n",
    "    \n",
    "    if regularization_coefficient == \"default\":\n",
    "        if distortion == \"L2\":\n",
    "            regularization_coefficient = 0\n",
    "        elif distortion == \"local_euclidean\":\n",
    "            regularization_coefficient = 1e3\n",
    "    \n",
    "    i = mesh_index\n",
    "    x = data[i].pos\n",
    "    e = data[i].edge_index.t().to(DEVICE) # needs to be transposed\n",
    "    f = data[i].face.t().to(DEVICE) # needs to be transposed\n",
    "    y = data[i].y\n",
    "    t = target_class\n",
    "\n",
    "    # configure adversarial example components\n",
    "    builder = cw.CWBuilder(search_iterations=tuning_iterations)\n",
    "    builder.set_classifier(get_classifier(data, i))\n",
    "    builder.set_perturbation_type(perturbation, eigs_num=eigenvecs_number)\n",
    "    print(adversarial_coefficient)\n",
    "    builder.set_mesh(x, e, f).set_adversarial_coeff(adversarial_coefficient)\n",
    "    if t is not None: builder.set_target(t)\n",
    "    \n",
    "    if distortion==\"L2\":\n",
    "        builder.set_distortion_function(cw.L2_distortion)\n",
    "    elif distortion==\"local_euclidean\":\n",
    "        builder.set_distortion_function(cw.LocallyEuclideanDistortion(K=40))\n",
    "        builder.set_regularization_function(cw.centroid_regularizer)\n",
    "\n",
    "    builder.set_minimization_iterations(minimization_iterations).set_learning_rate(learning_rate)\n",
    "    adex = builder.build(usetqdm=\"standard\")\n",
    "    return adex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adex = CW_adversarial_example(\n",
    "data=traindata,\n",
    "mesh_index=0,\n",
    "target_class=1,\n",
    "perturbation=\"lowband\",\n",
    "learning_rate=5e-4, \n",
    "minimization_iterations=10,\n",
    "tuning_iterations=1)\n",
    "\n",
    "print(\"adversarial attack: \"+(\"successful\" if adex.is_successful else \"unsuccessful\"))\n",
    "compare(adex.pos, f, adex.perturbed_pos, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
