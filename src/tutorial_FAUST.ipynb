{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "First, we need to import all the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# built-in libraries\n",
    "import os \n",
    "\n",
    "# third party libraries\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import tqdm\n",
    "import torch \n",
    "import torch.nn.functional as func\n",
    "\n",
    "# repository modules\n",
    "import models\n",
    "import train\n",
    "import adversarial.carlini_wagner as cw\n",
    "import adversarial.pgd as pgd\n",
    "import dataset\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training and test data is loaded in memory using the `dataset` local module. Before using the FAUST dataset download it from [here](http://faust.is.tue.mpg.de/) and place it in `{repository-root}/datasets/faust/raw/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_ROOT = os.path.join(os.path.dirname(os.path.realpath('__file__')),\"..\")\n",
    "FAUST = os.path.join(REPO_ROOT,\"datasets/faust\")\n",
    "PARAMS_FILE = os.path.join(REPO_ROOT, \"model_data/data.pt\")\n",
    "\n",
    "traindata = dataset.FaustDataset(FAUST, train=True, test=False, transform_data=True)\n",
    "testdata = dataset.FaustDataset(FAUST, train=False, test=True,  transform_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can define the classifier for the human pose classefication task; download the classifier parameters from [here](https://drive.google.com/open?id=1IllCPPPcqFL3v8BDxCyswzEpxoGyXvMe). Move these parameters in `{repository-root}/model_data/data.pt` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.ChebnetClassifier(\n",
    "    param_conv_layers=[128,128,64,64],\n",
    "    D_t = traindata.downscale_matrices,\n",
    "    E_t = traindata.downscaled_edges,\n",
    "    num_classes = traindata.num_classes,\n",
    "    parameters_file=PARAMS_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and evaluation can be done through the `train` local module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train network\n",
    "train.train(\n",
    "    train_data=traindata,\n",
    "    classifier=model,\n",
    "    parameters_file=PARAMS_FILE,\n",
    "    epoch_number=0)\n",
    "\n",
    "#compute accuracy\n",
    "accuracy, confusion_matrix = train.evaluate(eval_data=testdata, classifier=model)\n",
    "\n",
    "print(accuracy)\n",
    "plt.matshow(confusion_matrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = 0\n",
    "for mesh in tqdm.tqdm(traindata):\n",
    "    i, j = mesh.edge_index\n",
    "    xij = mesh.pos[i] - mesh.pos[j]\n",
    "    xij_norm = xij.norm(p=2, dim=-1)\n",
    "    v, _ = xij_norm.median(dim=-1)\n",
    "    sum +=v\n",
    "print(sum/len(traindata))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carlini & Wagner Method\n",
    "It is possible to create adversarial examples through the **AdversarialExampleBuilder** and **AdversarialExample** classes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a random mesh from the dataset and a random target class\n",
    "import random\n",
    "i = random.randint(0, len(traindata)-1)\n",
    "x = traindata[i].pos\n",
    "e = traindata[i].edge_index.t() # needs to be transposed\n",
    "f = traindata[i].face.t() # needs to be transposed\n",
    "y = traindata[i].y\n",
    "t = random.randint(0, traindata.num_classes-1)\n",
    "eigs_num = 10\n",
    "\n",
    "# configure adversarial example components\n",
    "builder = cw.CWBuilder(search_iterations=1)\n",
    "builder.set_classifier(model)\n",
    "builder.set_perturbation_type(\"lowband\", eigs_num=eigs_num)\n",
    "builder.set_mesh(x, e, f)\n",
    "builder.set_target(t)\n",
    "builder.set_distortion_function(cw.L2_distortion)\n",
    "builder.set_minimization_iterations(100).set_learning_rate(1e-4)\n",
    "adex = builder.build(usetqdm=\"standard\")\n",
    "print(\"adversarial attack: \"+(\"successful\" if adex.is_successful else \"unsuccessful\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(adex.perturbed_pos, f, (x-adex.perturbed_pos).norm(p=2,dim=-1))\n",
    "compare(adex.pos, f, adex.perturbed_pos,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can finally see the actual adversarial example using **Plotly** (note: you need to install plotly before-hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "def visualize(pos, faces, intensity=None):\n",
    "  cpu = torch.device(\"cpu\")\n",
    "  if type(pos) != np.ndarray:\n",
    "    pos = pos.to(cpu).clone().detach().numpy()\n",
    "  if pos.shape[-1] != 3:\n",
    "    raise ValueError(\"Vertices positions must have shape [n,3]\")\n",
    "  if type(faces) != np.ndarray:\n",
    "    faces = faces.to(cpu).clone().detach().numpy()\n",
    "  if faces.shape[-1] != 3:\n",
    "    raise ValueError(\"Face indices must have shape [m,3]\") \n",
    "  if intensity is None:\n",
    "    intensity = np.ones([pos.shape[0]])\n",
    "  elif type(intensity) != np.ndarray:\n",
    "    intensity = intensity.to(cpu).clone().detach().numpy()\n",
    "\n",
    "  x, z, y = pos.T\n",
    "  i, j, k = faces.T\n",
    "\n",
    "  mesh = go.Mesh3d(x=x, y=y, z=z,\n",
    "            color='lightpink',\n",
    "            intensity=intensity,\n",
    "            opacity=1,\n",
    "            colorscale=[[0, 'gold'],[0.5, 'mediumturquoise'],[1, 'magenta']],\n",
    "            i=i, j=j, k=k,\n",
    "            showscale=True)\n",
    "  layout = go.Layout(scene=go.layout.Scene(aspectmode=\"data\")) \n",
    "\n",
    "  #pio.renderers.default=\"plotly_mimetype\"\n",
    "  fig = go.Figure(data=[mesh],\n",
    "                  layout=layout)\n",
    "  fig.update_layout(\n",
    "      autosize=True,\n",
    "      margin=dict(l=20, r=20, t=20, b=20),\n",
    "      paper_bgcolor=\"LightSteelBlue\")\n",
    "  fig.show()\n",
    "    \n",
    "def compare(pos1, faces1, pos2, faces2):\n",
    "    n,m = pos1.shape[0], pos2.shape[0]\n",
    "    tmpx = torch.cat([pos1, pos2],dim=0)\n",
    "    tmpf = torch.cat([faces1, faces2+n], dim=0)\n",
    "    color = torch.zeros([n+m],dtype=pos1.dtype, device=pos1.device)\n",
    "    color[n:] = (pos1-pos2).norm(p=2,dim=-1)\n",
    "    visualize(tmpx, tmpf,color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projected Gradient Descent Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import adversarial.pgd as pgd\n",
    "\n",
    "i = random.randint(0, len(traindata)-1)\n",
    "x = traindata[i].pos\n",
    "e = traindata[i].edge_index.t() # needs to be transposed\n",
    "f = traindata[i].face.t() # needs to be transposed\n",
    "y = traindata[i].y\n",
    "N=20\n",
    "\n",
    "if model(x).argmax() == y:\n",
    "    builder = pgd.PGDBuilder().set_iterations(1).set_epsilon(0.005).set_alpha(0.005).set_eigs_number(100).set_projection(pgd.lowband_filter)\n",
    "    #builder = pgd.FGSMBuilder().set_epsilon(0.01)\n",
    "    builder.set_mesh(x,e,f).set_classifier(model)\n",
    "    adex = builder.build(usetqdm=\"standard\")\n",
    "    print(\"successful: {}\".format(adex.is_successful))\n",
    "    print(\"adversarial example's prediction: {}\".format(model(adex.perturbed_pos).argmax()))\n",
    "    print(\"ground-truth: {}\".format(model(adex.pos).argmax()))\n",
    "    #visualize(adex.perturbed_pos, f, (x-adex.perturbed_pos).norm(p=2,dim=-1))\n",
    "\n",
    "    n = x.shape[0]\n",
    "    tmpx = torch.cat([x, adex.perturbed_pos],dim=0)\n",
    "    tmpf = torch.cat([f, f+n], dim=0)\n",
    "    color = torch.zeros([n*2],dtype=x.dtype, device=x.device)\n",
    "    color[n:] = (x-adex.perturbed_pos).norm(p=2,dim=-1)\n",
    "    visualize(tmpx, tmpf,color)\n",
    "else:\n",
    "    print(\"Oh no!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(adex.perturbed_pos -adex.pos).abs().max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(tmpx[n:], f, color[n:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import adversarial.carlini_wagner as cw\n",
    "l2,l2squared = cw.L2_distortion(adex)\n",
    "\n",
    "l2, torch.sqrt(l2squared)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
